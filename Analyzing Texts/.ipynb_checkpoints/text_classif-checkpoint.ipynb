{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid green 2px; padding: 20px\">\n",
    "<b>Привет, Наталья!</b>\n",
    "\n",
    "Меня зовут Александр Пономаренко, и я буду проверять твой проект. Предлагаю общаться на «ты» :) Но если это не удобно - дай знать, и мы перейдем на \"вы\". \n",
    "\n",
    "Моя основная цель — не указать на совершенные тобою ошибки, а поделиться своим опытом и помочь тебе стать data science. Ты уже проделал большую работу над проектом, но давай сделаем его еще лучше. Ниже ты найдешь мои комментарии - **пожалуйста, не перемещай, не изменяй и не удаляй их**. Увидев у тебя ошибку, в первый раз я лишь укажу на ее наличие и дам тебе возможность самой найти и исправить ее. На реальной работе твой начальник будет поступать так же, а я пытаюсь подготовить тебя именно к работе аналитиком. Но если ты пока не справишься с такой задачей - при следующей проверке я дам более точную подсказку. Я буду использовать цветовую разметку:\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Комментарий ревьюера ❌:</b> Так выделены самые важные замечания. Без их отработки проект не будет принят. </div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера ⚠️:</b> Так выделены небольшие замечания. Я надеюсь, что их ты тоже учтешь - твой проект от этого станет только лучше. Но настаивать на их отработке не буду.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Так я выделяю все остальные комментарии.</div>\n",
    "\n",
    "Давай работать над проектом в диалоге: **если ты что-то меняешь в проекте или отвечаешь на мои комменатри — пиши об этом.** Мне будет легче отследить изменения, если ты выделишь свои комментарии:\n",
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Например, вот так.</div>\n",
    "\n",
    "Всё это поможет выполнить повторную проверку твоего проекта оперативнее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Привет, спасибо за проверку проекта. Исправила твои замечания: ускорила лемматизацию текста и убрала деление на валдиационную выборку</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Загрузим необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\seluy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\seluy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\seluy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\seluy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Посмотрим наши данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                           Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                           Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"/datasets/toxic_comments.csv\", index_col=[0])  \n",
    "except:\n",
    "    df = pd.read_csv(\"toxic_comments.csv\", index_col=[0])\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Огонь, данные на месте:)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков в данных нет, с типами тоже все в порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соотношения классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    89.838787\n",
       "1    10.161213\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toxic.value_counts()/df.shape[0]*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество дубликатов: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Количество дубликатов: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дальнейшего использования 159272 очень большой датасет, поэтому сделаем sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "соотношение классов в датасете corpus\n",
      " 0    89.78\n",
      "1    10.22\n",
      "Name: toxic, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sample_size = 40000\n",
    "corpus = df.sample(n=sample_size,random_state=0).reset_index(drop=True)\n",
    "print('соотношение классов в датасете corpus\\n', corpus.toxic.value_counts()/corpus.shape[0]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Хорошо, молодец, что сохранила баланс классов:)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Очистим текст от лишних символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)   \n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['text'] = corpus['text'].apply(clear_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                           Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                           Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Лемматизируем текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordnet – это большая, свободно распространяемая и общедоступная лексическая база данных для английского языка с целью установления структурированных семантических отношений между словами.\n",
    "Будем использовать  Wordnet Lemmatizer с соответствующим POS-тегом (part of speech - часть речи)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция РОS-тэгирования слов:\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,               #прилагательное\n",
    "                \"N\": wordnet.NOUN,              #существительное\n",
    "                \"V\": wordnet.VERB,              #глагол\n",
    "                \"R\": wordnet.ADV                #наречие\n",
    "               }  \n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Функцию леммализации тектов постов:\n",
    "def lemm_text(text):\n",
    "    text = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 40000/40000 [01:52<00:00, 355.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 16s\n",
      "Wall time: 1min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_corpus = []\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "for doc in tqdm(nlp.pipe(corpus['text'], batch_size=64, n_process=-1, disable=[\"parser\", \"ner\"]), total=len(corpus['text'])):\n",
    "    word_list = [tok.lemma_ for tok in doc]\n",
    "    new_corpus.append(' '.join(word_list))\n",
    "    \n",
    "corpus['lem_text'] = new_corpus  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b>\n",
    "    \n",
    "Так же можешь попробовать использовать spacy:\n",
    "    \n",
    "```python\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemmatize_spacy(text):\n",
    "    return \" \".join([token.lemma_ for token in nlp(text)])\n",
    "\n",
    "data['lemm_spacy'] = data['text'].progress_apply(lemmatize_spacy)     \n",
    "```\n",
    "\n",
    "Вот так можно следить за выполнением функции (как раз выше его использовал)\n",
    "\n",
    "```python\n",
    "    \n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "data['text'] = data['text'].progress_apply(lemmatize_text) \n",
    "```\n",
    "Где *lemmatize_text* - функция\n",
    "\n",
    "    \n",
    "P.S Кстати можно ускорить spacy ( раз в 5 +-)\n",
    "    \n",
    "```python\n",
    "new_corpus = []\n",
    "\n",
    "for doc in tqdm(nlp.pipe(data['text'], batch_size=64, n_process=-1, disable=[\"parser\", \"ner\"]), total=len(data['text'])):\n",
    "    word_list = [tok.lemma_ for tok in doc]\n",
    "    new_corpus.append(' '.join(word_list))\n",
    "    \n",
    "data['lemm_spacy_new'] = new_corpus   \n",
    "    \n",
    "    \n",
    "```\n",
    "    \n",
    "Для больших объемов текста ```SpaCy``` рекомендует использовать ```nlp.pipe```, который может работать в пакетах ```batch_size```(Допустим ```batch_size=64```, тогда все наши данные делятся на 64 пакета (как прям в фолдах, только там мы пишем число на сколько поделить наши данные (3/5/10 частей),а тут пишем, сколько данных отдать в обработку)  и имеет встроенную поддержку многопроцессорной обработки ```n_process``` (аналог ```n_jobs``` для GridSearchCV).\n",
    "\n",
    "Кроме того, нужно убедиться, что мы отключили все элементы конвейера, которые мы не планируем использовать, поскольку они просто потратят время на обработку. Если мы выполняем только лемматизацию, то необходимо передать ```disable=[\"parser\", \"ner\"]``` к ```nlp.pipe```.\n",
    "    \n",
    "    \n",
    "P.S.S Если запустишь ```nlp.pipe```, то первое время нужно подождать прежде, чем начнется обработка \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Разделим выборку на обучающую и тренировочную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделяю выборки в соотношении 80/20:\n",
    "features = corpus['lem_text'] \n",
    "target = corpus['toxic']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, \n",
    "                                                                              target, \n",
    "                                                                              test_size=.2, \n",
    "                                                                              random_state=12345)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Комментарий ревьюера ❌:</b> А зачем валидационная выборка, если ты используешь кросс валидацию? Ранее мы использовали валидационную выборку для подбора параметров, сейчас на себя взял эту роль GridSearchCV у него внутри train делится на train/valid, поэтому features_valid нам просто не нужен\n",
    "    \n",
    "    \n",
    "P.S С помощью best_score_ можно узнать лучшую метрику у GridSearchCV\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Исправила</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000,)\n",
      "(32000,)\n",
      "(8000,)\n",
      "(8000,)\n"
     ]
    }
   ],
   "source": [
    "for i in [features_train, target_train,features_test, target_test]:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**:\n",
    "- Очистили тексты комментариев от ненужных знаков и леммализировали их\n",
    "- Разбили данные на обучающуюи тестовую выборку в соотношении 80/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Логистическая регрессиия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 логистической регрессии = 0.7534\n",
      "при параметрах {'lr__C': 10, 'lr__class_weight': 'balanced', 'lr__max_iter': 200, 'lr__random_state': 12345, 'lr__solver': 'newton-cg'}\n",
      "CPU times: total: 6.27 s\n",
      "Wall time: 47.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english', sublinear_tf=True)), \n",
    "                     (\"lr\", LogisticRegression())])\n",
    "    \n",
    "parameters = {'lr__solver': ('liblinear', 'saga','newton-cg', 'lbfgs'),\n",
    "              'lr__C': (.1, 1, 5, 10),\n",
    "              'lr__random_state': ([12345]),\n",
    "              'lr__max_iter': ([200]),\n",
    "              'lr__class_weight': (['balanced'])} \n",
    "\n",
    "lr = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "lr.fit(features_train, target_train)\n",
    "\n",
    "mts = lr.cv_results_['mean_test_score']\n",
    "lr_train_f1 = max(mts)\n",
    "\n",
    "print('F1 логистической регрессии =', round(lr_train_f1,4))\n",
    "print('при параметрах', lr.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b>Круто, что используешь Pipeline:) Смотри, округлять стоит все же после 3-4 знака, иначе не понятно 0.745 или 0.752 получилось, так как после округления мы получим все равно 0.75\n",
    "    \n",
    "    \n",
    "    \n",
    "Кстати, для Tfidf тоже можно поподбирать параметры:\n",
    "```python\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('logreg', LogisticRegression(random_state=42)),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'logreg__C': [1,2,6]\n",
    "}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, scoring='f1')\n",
    "grid_search_tune.fit(train_features, train_targets)\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 дерева решений = 0.6158\n",
      "при параметрах {'dtc__class_weight': 'balanced', 'dtc__max_depth': 23, 'dtc__random_state': 12345}\n",
      "CPU times: total: 9.41 s\n",
      "Wall time: 56.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"dtc\", DecisionTreeClassifier())])\n",
    "    \n",
    "parameters = {'dtc__max_depth': ([x for x in range(1, 25)]),\n",
    "              'dtc__random_state': ([12345]), \n",
    "              'dtc__class_weight': (['balanced'])}\n",
    "\n",
    "tree = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "tree.fit(features_train, target_train)\n",
    "\n",
    "mts = tree.cv_results_['mean_test_score']\n",
    "dtc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 дерева решений =', round(dtc_train_f1,4))\n",
    "print('при параметрах', tree.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 CatBoostClassifier = 0.7084\n",
      "при параметрах {'cbc__class_weights': (1, 1), 'cbc__iterations': 200, 'cbc__verbose': False}\n",
      "CPU times: total: 8min 16s\n",
      "Wall time: 6min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"cbc\", CatBoostClassifier())])\n",
    "    \n",
    "parameters = {'cbc__verbose': ([False]),\n",
    "              'cbc__iterations': ([200]),\n",
    "              'cbc__class_weights':([(1, 1), (1, 11)])} #вот вообще не уверена, что class_weights тут нужен\n",
    "\n",
    "cat = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "cat.fit(features_train, target_train)\n",
    "\n",
    "mts = cat.cv_results_['mean_test_score']\n",
    "cbc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 CatBoostClassifier =', round(cbc_train_f1,4))\n",
    "print('при параметрах', cat.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 случайного леса = 0.3533\n",
      "при параметрах {'rfc__class_weight': 'balanced', 'rfc__criterion': 'entropy', 'rfc__max_depth': 9, 'rfc__n_estimators': 28, 'rfc__random_state': 12345}\n",
      "CPU times: total: 40.3 s\n",
      "Wall time: 4min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"rfc\", RandomForestClassifier())])\n",
    "    \n",
    "parameters = {'rfc__n_estimators': ([x for x in range(10, 30)]),\n",
    "              'rfc__random_state': ([12345]),\n",
    "              'rfc__max_depth': ([x for x in range(1, 10)]),\n",
    "              'rfc__criterion': (['entropy']),\n",
    "              'rfc__class_weight': (['balanced'])}\n",
    "\n",
    "rf = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "mts = rf.cv_results_['mean_test_score']\n",
    "rfc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 случайного леса =', round(rfc_train_f1,4))\n",
    "print('при параметрах', rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Сравнение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 на обучающей выборке</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.753433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.708362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.353299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        F1 на обучающей выборке\n",
       "LogisticRegression                     0.753433\n",
       "CatBoostClassifier                     0.708362\n",
       "DecisionTreeClassifier                 0.615838\n",
       "RandomForestClassifier                 0.353299"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создаю сводную таблицу по показателям F1\n",
    "index = ['LogisticRegression',\n",
    "         'DecisionTreeClassifier',\n",
    "         'CatBoostClassifier',\n",
    "         'RandomForestClassifier',\n",
    "        ]\n",
    "\n",
    "data = {'F1 на обучающей выборке': [lr_train_f1,\n",
    "                                    dtc_train_f1,\n",
    "                                    cbc_train_f1,\n",
    "                                    rfc_train_f1],\n",
    "        }\n",
    "\n",
    "f1_data = pd.DataFrame(data=data, index=index)\n",
    "\n",
    "f1_data.sort_values(by='F1 на обучающей выборке', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшей моделью я считаю логистическую регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Тестирование лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "финальный F1 логистической регрессии = 0.7744733581164808\n"
     ]
    }
   ],
   "source": [
    "predictions_test = lr.predict(features_test)\n",
    "lr_test_f1 = f1_score(target_test, predictions_test)\n",
    "print('финальный F1 логистической регрессии =', lr_test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b>Отлично, протестировала корректно:)\n",
    "    \n",
    "    \n",
    "P.S Если, что то можешь не обучать еще раз все модели, главное поправить разбиение на выборки;)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы проделали следующие шаги:\n",
    "\n",
    "- загрузили данные и провели их предобработку - очистили текст, провели лемматизацию\n",
    "- обучилм 4 модели LogisticRegression, DecisionTreeClassifier, CatBoostClassifier, RandomForestClassifier с разными гиперпараметрами и выборками, посмотрели результаты на валидационной выборке\n",
    "- По показателю F1 лучшей выбрали LogisticRegression, провели тестирование и результатом оказалось 0.774, что удовлетворяет требованию задания\n",
    "- Аутсайдером среди моделей стали RandomForestClassifier и DecisionTreeClassifier, так как дали наименьшее F1.\n",
    "\n",
    "Итак, наилучшей моделью стала LogisticRegression, которая на тестировании показала F1 = 0.774"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> \n",
    "\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множество реализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Итоговый комментарий ревьюера</b></font>\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b>Наталья, получился хороший проект! \n",
    "    \n",
    "Если есть  если есть какие либо вопросы я с удовольствием на них отвечу:) <br> Исправь, пожалуйста, замечания и жду проект на следующую проверку:) </div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
